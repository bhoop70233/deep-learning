{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import section"
      ],
      "metadata": {
        "id": "4IXH2tzaECCH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fAw9C7-ACaRv"
      },
      "outputs": [],
      "source": [
        "from pandas import read_csv # read CSV (Comma- Separated Values ) files into a DataFrame\n",
        "import numpy as np # numerical computations,working with arrays,mathematical operations,random number generation\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "import tensorflow as tf # Import TensorFlow\n",
        "\n",
        "\n",
        "\n",
        "K = tf.keras.backend\n",
        "\n",
        "from keras import Model\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Input,Dense,SimpleRNN\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.metrics import mean_squared_error\n",
        "from keras.models import Sequential # model in keras is a straightforward way to build a neural network layer by layer .it's ideal ofr models where each layer has exactly one input tensor and one output tensor\n",
        "from keras.metrics import mean_squared_error # import from keras.losses for use as a loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the Dataset\n"
      ],
      "metadata": {
        "id": "5P8pW2vqLEKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fib_seq(n,scale_data=True):\n",
        "  #Get the Fibonacci sequence\n",
        "  seq=np.zeros(n)\n",
        "  fib_n1=0.0\n",
        "  fib_n=1.0\n",
        "  for i in range(n):\n",
        "    seq[i]=fib_n1+fib_n\n",
        "    fib_n1=fib_n\n",
        "    fib_n=seq[i]\n",
        "  scaler=[]\n",
        "  if scale_data:\n",
        "    scaler=MinMaxScaler(feature_range=(0,1))\n",
        "    seq=np.reshape(seq,(n,1))\n",
        "    seq=scaler.fit_transform(seq).flatten()\n",
        "  return seq,scaler\n",
        "\n",
        "fib_seq=get_fib_seq(10,False)[0]\n",
        "print(fib_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqKaXq0FJ_K5",
        "outputId": "d5f8a994-bc02-44c9-c6ce-ffca0239fbf7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.  2.  3.  5.  8. 13. 21. 34. 55. 89.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fib_XY(total_fib_numbers,time_steps,train_percent,scale_data=True):\n",
        "  dat,scaler=get_fib_seq(total_fib_numbers,scale_data)\n",
        "  Y_ind=np.arange(time_steps,len(dat),1)\n",
        "  Y=dat[Y_ind]\n",
        "  rows_x=len(Y)\n",
        "  X=dat[0:rows_x]\n",
        "  for i in range(time_steps-1):\n",
        "    temp=dat[i+1:rows_x+i+1]\n",
        "    X=np.column_stack((X,temp))\n",
        "\n",
        "  # random permutation with fixed seed\n",
        "  rand=np.random.RandomState(seed=13)\n",
        "  idx=rand.permutation(rows_x)\n",
        "  split=int(train_percent*rows_x)\n",
        "  train_ind=idx[0:split]\n",
        "  test_ind=idx[split:]\n",
        "  trainX=X[train_ind]\n",
        "  trainY=Y[train_ind]\n",
        "  testX=X[test_ind]\n",
        "  testY=Y[test_ind]\n",
        "  trainX=np.reshape(trainX,(len(trainX),time_steps,1))\n",
        "  testX=np.reshape(testX,(len(testX),time_steps,1))\n",
        "  return trainX,trainY,testX,testY,scaler\n",
        "\n",
        "trainX,trainY,testX,testY,scaler=get_fib_XY(12,3,0.7,False)\n",
        "print('trainX=',trainX)\n",
        "print('trainY = ',trainY)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQRSAZxmMVBO",
        "outputId": "37cc3ba9-c4ba-4223-d69a-6e9062e34597"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainX= [[[ 8.]\n",
            "  [13.]\n",
            "  [21.]]\n",
            "\n",
            " [[ 5.]\n",
            "  [ 8.]\n",
            "  [13.]]\n",
            "\n",
            " [[ 2.]\n",
            "  [ 3.]\n",
            "  [ 5.]]\n",
            "\n",
            " [[13.]\n",
            "  [21.]\n",
            "  [34.]]\n",
            "\n",
            " [[21.]\n",
            "  [34.]\n",
            "  [55.]]\n",
            "\n",
            " [[34.]\n",
            "  [55.]\n",
            "  [89.]]]\n",
            "trainY =  [ 34.  21.   8.  55.  89. 144.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Up the network"
      ],
      "metadata": {
        "id": "mTAkkdtHO8nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up parameters\n",
        "time_steps=20\n",
        "hidden_units=2\n",
        "epochs=30\n",
        "\n",
        "#Create a traditional RNN network\n",
        "def create_RNN(hidden_units,dense_units,input_shape,activation):\n",
        "  model=Sequential()\n",
        "  model.add(SimpleRNN(hidden_units,input_shape=input_shape,activation=activation[0]))\n",
        "  model.add(Dense(units=dense_units,activation=activation[1]))\n",
        "  model.compile(loss='mse',optimizer='adam')\n",
        "  return model\n",
        "\n",
        "model_RNN=create_RNN(hidden_units=hidden_units,dense_units=1,input_shape=(time_steps,1),activation=['tanh','tanh'])\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "qcPzw-4RO4p1",
        "outputId": "190d7a04-5c26-400c-ae80-eb7c73fba0ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m3\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11\u001b[0m (44.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> (44.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11\u001b[0m (44.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> (44.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Network And Evaluate"
      ],
      "metadata": {
        "id": "e5_oj0AWQQxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate the dataset\n",
        "trainX,trainY,testX,testY,scaler=get_fib_XY(1200,time_steps,0.7)\n",
        "model_RNN.fit(trainX,trainY,epochs=epochs,batch_size=1,verbose=2)\n",
        "\n",
        "#Evalute model\n",
        "train_mse=model_RNN.evaluate(trainX,trainY)\n",
        "test_mse=model_RNN.evaluate(testX,testY)\n",
        "\n",
        "#Print error\n",
        "print(\"Train set MSE =\",train_mse)\n",
        "print(\"Test set MSE =\",test_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTSsqNsuQKOS",
        "outputId": "75416c6d-c1f0-45c7-8e19-954768e10cfc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "826/826 - 2s - 2ms/step - loss: 7.0117e-05\n",
            "Epoch 2/30\n",
            "826/826 - 2s - 3ms/step - loss: 6.9179e-05\n",
            "Epoch 3/30\n",
            "826/826 - 3s - 4ms/step - loss: 6.6072e-05\n",
            "Epoch 4/30\n",
            "826/826 - 4s - 5ms/step - loss: 6.6385e-05\n",
            "Epoch 5/30\n",
            "826/826 - 2s - 2ms/step - loss: 6.4761e-05\n",
            "Epoch 6/30\n",
            "826/826 - 3s - 3ms/step - loss: 6.5112e-05\n",
            "Epoch 7/30\n",
            "826/826 - 3s - 3ms/step - loss: 6.3880e-05\n",
            "Epoch 8/30\n",
            "826/826 - 5s - 5ms/step - loss: 6.3367e-05\n",
            "Epoch 9/30\n",
            "826/826 - 2s - 2ms/step - loss: 6.3467e-05\n",
            "Epoch 10/30\n",
            "826/826 - 3s - 4ms/step - loss: 6.4160e-05\n",
            "Epoch 11/30\n",
            "826/826 - 2s - 3ms/step - loss: 6.2961e-05\n",
            "Epoch 12/30\n",
            "826/826 - 3s - 3ms/step - loss: 6.3692e-05\n",
            "Epoch 13/30\n",
            "826/826 - 2s - 2ms/step - loss: 6.0532e-05\n",
            "Epoch 14/30\n",
            "826/826 - 3s - 3ms/step - loss: 5.8078e-05\n",
            "Epoch 15/30\n",
            "826/826 - 2s - 2ms/step - loss: 6.2592e-05\n",
            "Epoch 16/30\n",
            "826/826 - 2s - 2ms/step - loss: 6.0767e-05\n",
            "Epoch 17/30\n",
            "826/826 - 3s - 4ms/step - loss: 6.0394e-05\n",
            "Epoch 18/30\n",
            "826/826 - 4s - 5ms/step - loss: 6.0358e-05\n",
            "Epoch 19/30\n",
            "826/826 - 3s - 3ms/step - loss: 5.8976e-05\n",
            "Epoch 20/30\n",
            "826/826 - 3s - 3ms/step - loss: 5.8318e-05\n",
            "Epoch 21/30\n",
            "826/826 - 3s - 4ms/step - loss: 5.9917e-05\n",
            "Epoch 22/30\n",
            "826/826 - 3s - 3ms/step - loss: 5.7714e-05\n",
            "Epoch 23/30\n",
            "826/826 - 2s - 2ms/step - loss: 5.6934e-05\n",
            "Epoch 24/30\n",
            "826/826 - 3s - 3ms/step - loss: 5.9311e-05\n",
            "Epoch 25/30\n",
            "826/826 - 3s - 3ms/step - loss: 5.8400e-05\n",
            "Epoch 26/30\n",
            "826/826 - 2s - 2ms/step - loss: 5.7327e-05\n",
            "Epoch 27/30\n",
            "826/826 - 3s - 4ms/step - loss: 5.5972e-05\n",
            "Epoch 28/30\n",
            "826/826 - 2s - 2ms/step - loss: 5.8939e-05\n",
            "Epoch 29/30\n",
            "826/826 - 3s - 3ms/step - loss: 5.5780e-05\n",
            "Epoch 30/30\n",
            "826/826 - 2s - 2ms/step - loss: 5.6149e-05\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7410e-05  \n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7010e-05 \n",
            "Train set MSE = 4.615318539435975e-05\n",
            "Test set MSE = 3.197569458279759e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Call Method for the Attention LAyer"
      ],
      "metadata": {
        "id": "3Uzi7l8OSC-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add attention layer to the deep learning network\n",
        "class attention(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1),\n",
        "                               initializer='random_normal', trainable=True)\n",
        "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1),\n",
        "                               initializer='zeros', trainable=True)\n",
        "        super(attention, self).build(input_shape)\n",
        "\n",
        "    def call(self,x):\n",
        "        # Alignment scores. Pass them through tanh function\n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        # Remove dimension of size 1\n",
        "        e = K.squeeze(e, axis=-1)\n",
        "        # Compute the weights\n",
        "        alpha = K.softmax(e)\n",
        "        # Reshape to tensorFlow format\n",
        "        alpha = K.expand_dims(alpha, axis=-1)\n",
        "        # Compute the context vector\n",
        "        context = x * alpha\n",
        "        context = K.sum(context, axis=1)\n",
        "        return context"
      ],
      "metadata": {
        "id": "406Z0Js3RNBx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN Network with Attention Layer"
      ],
      "metadata": {
        "id": "ZGLNCshAVkvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_RNN_with_attention(hidden_units, dense_units, input_shape, activation):\n",
        "    x=Input(shape=input_shape)\n",
        "    RNN_layer = SimpleRNN(hidden_units, return_sequences=True, activation=activation)(x)\n",
        "    attention_layer = attention()(RNN_layer)\n",
        "    outputs=Dense(dense_units, trainable=True, activation=activation)(attention_layer)\n",
        "    model=Model(x,outputs)\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "model_attention = create_RNN_with_attention(hidden_units=hidden_units, dense_units=1,\n",
        "                                  input_shape=(time_steps,1), activation='tanh')\n",
        "model_attention.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "4Iv3g7Z6Vi4d",
        "outputId": "01a57368-2b30-4d80-c799-8f09bcb82dc1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m2\u001b[0m)               │               \u001b[38;5;34m8\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_1 (\u001b[38;5;33mattention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m22\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m3\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33\u001b[0m (132.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> (132.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33\u001b[0m (132.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> (132.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evalute the Deep Learning Network with attention"
      ],
      "metadata": {
        "id": "gYOHMlTFZ6x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_attention.fit(trainX,trainY,epochs=epochs,batch_size=1,verbose=2)\n",
        "\n",
        "#Evalute model\n",
        "train_mse_attn=model_attention.evaluate(trainX,trainY)\n",
        "test_mse_attn=model_attention.evaluate(testX,testY)\n",
        "\n",
        "#Print error\n",
        "print(\"Train set MSE with attention =\",train_mse_attn)\n",
        "print(\"Test set MSE with attention =\",test_mse_attn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVHeO85wXDIb",
        "outputId": "344f66a8-4086-424c-e704-5bc19773a6e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "826/826 - 4s - 4ms/step - loss: 0.0015\n",
            "Epoch 2/30\n",
            "826/826 - 3s - 3ms/step - loss: 0.0015\n",
            "Epoch 3/30\n",
            "826/826 - 3s - 4ms/step - loss: 0.0015\n",
            "Epoch 4/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0015\n",
            "Epoch 5/30\n",
            "826/826 - 3s - 3ms/step - loss: 0.0015\n",
            "Epoch 6/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0015\n",
            "Epoch 7/30\n",
            "826/826 - 3s - 3ms/step - loss: 0.0015\n",
            "Epoch 8/30\n",
            "826/826 - 3s - 4ms/step - loss: 0.0015\n",
            "Epoch 9/30\n",
            "826/826 - 3s - 3ms/step - loss: 0.0015\n",
            "Epoch 10/30\n",
            "826/826 - 5s - 6ms/step - loss: 0.0014\n",
            "Epoch 11/30\n",
            "826/826 - 5s - 6ms/step - loss: 0.0014\n",
            "Epoch 12/30\n",
            "826/826 - 3s - 3ms/step - loss: 0.0014\n",
            "Epoch 13/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0014\n",
            "Epoch 14/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0014\n",
            "Epoch 15/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0014\n",
            "Epoch 16/30\n",
            "826/826 - 3s - 3ms/step - loss: 0.0014\n",
            "Epoch 17/30\n",
            "826/826 - 4s - 4ms/step - loss: 0.0014\n",
            "Epoch 18/30\n",
            "826/826 - 4s - 5ms/step - loss: 0.0013\n",
            "Epoch 19/30\n",
            "826/826 - 3s - 3ms/step - loss: 0.0013\n",
            "Epoch 20/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0013\n",
            "Epoch 21/30\n",
            "826/826 - 3s - 4ms/step - loss: 0.0012\n",
            "Epoch 22/30\n",
            "826/826 - 5s - 5ms/step - loss: 0.0012\n",
            "Epoch 23/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0012\n",
            "Epoch 24/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0011\n",
            "Epoch 25/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0011\n",
            "Epoch 26/30\n",
            "826/826 - 3s - 4ms/step - loss: 0.0011\n",
            "Epoch 27/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0010\n",
            "Epoch 28/30\n",
            "826/826 - 2s - 3ms/step - loss: 9.5454e-04\n",
            "Epoch 29/30\n",
            "826/826 - 3s - 3ms/step - loss: 9.0857e-04\n",
            "Epoch 30/30\n",
            "826/826 - 2s - 3ms/step - loss: 8.5056e-04\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0621e-04  \n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9362e-04 \n",
            "Train set MSE with attention = 0.0007448239484801888\n",
            "Test set MSE with attention = 0.0005781885120086372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consolidated Code\n"
      ],
      "metadata": {
        "id": "58FsCeojbOd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "from keras import Model\n",
        "from keras.layers import Layer\n",
        "K = tf.keras.backend\n",
        "from keras.layers import Input,Dense,SimpleRNN\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "Q270FCiIa3X4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare data\n",
        "def get_fib_seq(n,scale_data=True):\n",
        "  #Get the Fibonacci sequence\n",
        "  seq=np.zeros(n)\n",
        "  fib_n1=0.0\n",
        "  fib_n=1.0\n",
        "  for i in range(n):\n",
        "    seq[i]=fib_n1+fib_n\n",
        "    fib_n1=fib_n\n",
        "    fib_n=seq[i]\n",
        "\n",
        "  scaler=[]\n",
        "  if scale_data:\n",
        "    scaler=MinMaxScaler(feature_range=(0,1))\n",
        "    seq=np.reshape(seq,(n,1))\n",
        "    seq=scaler.fit_transform(seq).flatten()\n",
        "\n",
        "  return seq,scaler\n",
        "\n",
        "def get_fib_XY(total_fib_numbers,time_steps,train_percent,scale_data=True):\n",
        "  dat,scaler=get_fib_seq(total_fib_numbers,scale_data)\n",
        "  Y_ind=np.arange(time_steps,len(dat),1)\n",
        "  Y=dat[Y_ind]\n",
        "  rows_x=len(Y)\n",
        "  X=dat[0:rows_x]\n",
        "  for i in range(time_steps-1):\n",
        "    temp=dat[i+1:rows_x+i+1]\n",
        "    X=np.column_stack((X,temp))\n",
        "  # random permutation with fixed seed\n",
        "  rand=np.random.RandomSate(seed=13)\n",
        "  idx=rand.permutation(rows_x)\n",
        "  split=int(train_percent*rows_x)\n",
        "  train_ind=idx[0:split]\n",
        "  test_ind=idx[split:]\n",
        "  trainX=X[train_ind]\n",
        "  trainY=Y[train_ind]\n",
        "  testX=X[test_ind]\n",
        "  testY=Y[test_ind]\n",
        "  trainX=np.reshape(trainX,(len(trainX),time_steps,1))\n",
        "  testX=np.reshape(testX,(len(testX),time_steps,1))\n",
        "  return trainX,trainY,testX,testY,scaler\n",
        "\n",
        "#Set up parameters\n",
        "time_steps=20\n",
        "hidden_units=2\n",
        "epochs=30\n",
        "\n",
        "#Create a traditional RNN network\n",
        "def create_RNN(hidden_units,dense_units,input_shape,activation):\n",
        "  model=Sequential()\n",
        "  model.add(SimpleRNN(hidden_units,input_shape=input_shape,activation=activation[0]))\n",
        "  model.add(Dense(units=dense_units,activation=activation[1]))\n",
        "  model.compile(loss='mse',optimizer='adam')\n",
        "  return model\n",
        "\n",
        "  model_RNN=create_RNN(hidden_units=hidden_units,dense_units=1,input_shape=(time_steps,1),activation=['tanh','tanh'])\n",
        "\n",
        "  #Generate the daatset for the network\n",
        "  trainX,trainY,testX,testY,scaler=get_fib_XY(1200,time_steps,0.7)\n",
        "  #train the network\n",
        "  model_RNN.fit(trainX,trainY,epochs=epochs,batch_size=1,verbose=2)\n",
        "\n",
        "  #Evalute model\n",
        "  train_mse=model_RNN>evaluate(trainX,trainY)\n",
        "  test_mse=model_RNN.evaluate(testX,testY)\n",
        "\n",
        "  #Print error\n",
        "  print(\"Train set MSE = \",train_mse)\n",
        "  print(\"Test set MSE =\" ,test_mse)\n",
        "\n",
        "  #Add attention layer to the deep learning network\n",
        "  class attention(layer):\n",
        "    def __init__(self,**kwargs):\n",
        "      super(attention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "      self.W=self.add_weight(name='attention_weight',shape=(input_shape[-1],1),\n",
        "                             initializer='random_normal',trainable=True)\n",
        "      self.b=self.add_weight(name='attention_bias',shape=(input_shape[1],1),\n",
        "                             initializer='zeros',trainable=True)\n",
        "      super(attention,self).build(input_shape)\n",
        "\n",
        "\n",
        "    def call(self,x):\n",
        "      #Alignment scores .Pass them through tanh function\n",
        "      e=K.tanh(K.dot(x,self.W)+self.b)\n",
        "      #Remove dimension of size 1\n",
        "      e=K.squeeze(e,axis=-1)\n",
        "      #compute the weights\n",
        "      alpha=K.softmax(e)\n",
        "      #reshape to tensorflow format\n",
        "      alpha=K.expand_dims(alpha,axis=-1)\n",
        "      #compute the context vector\n",
        "      context=x*alpha\n",
        "      context=K.sum(context,axis=1)\n",
        "      return context\n",
        "\n",
        "def create_RNN_with_attention(hidden_units,dense_units,input_shape,activation):\n",
        "  x=Input(shape=input_shape)\n",
        "  RNN_layer=SimpleRNN(hidden_units,return_sequences=True,activation=activation)(x)\n",
        "  attention_layer=attention()(RNN_layer)\n",
        "  outputs=Dense(dense_units,trainable=True,activation=activation)(attention_layer)\n",
        "  model=Model(x,outputs)\n",
        "  model.compile(loss='mse',optimizer='adam')\n",
        "  return model\n",
        "\n",
        "model_attention=create_RNN_with_attention(hidden_units=hidden_units,dense_units=1,\n",
        "                                           input_shape=(time_steps,1),activation='tanh')\n",
        "\n",
        "\n",
        "#Create the model with attention ,train and evaluate\n",
        "model_attention=create_RNN_with_attention(hidden_units=hidden_units,dense_units=1,\n",
        "                                           input_shape=(time_steps,1),activation='tanh')\n",
        "model_attention.summary()\n",
        "model_attention.fit(trainX,trainY,epochs=epochs,batch_size=1,verbose=2)\n",
        "\n",
        "#Evalute model\n",
        "train_mse_attn=model_attention.evaluate(trainX,trainY)\n",
        "test_mse_attn=model_attention.evaluate(testX,testY)\n",
        "\n",
        "#Print error\n",
        "print(\"Train set MSE with attention =\",train_mse_attn)\n",
        "print(\"Test set MSE with attention =\",test_mse_attn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EMia_SuccHNX",
        "outputId": "fd0bf019-f50f-464b-f22e-25d5b04e0470"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_5 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m2\u001b[0m)               │               \u001b[38;5;34m8\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_3 (\u001b[38;5;33mattention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m22\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m3\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33\u001b[0m (132.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> (132.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33\u001b[0m (132.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> (132.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "826/826 - 4s - 5ms/step - loss: 0.0014\n",
            "Epoch 2/30\n",
            "826/826 - 3s - 3ms/step - loss: 0.0014\n",
            "Epoch 3/30\n",
            "826/826 - 4s - 5ms/step - loss: 0.0013\n",
            "Epoch 4/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0013\n",
            "Epoch 5/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0013\n",
            "Epoch 6/30\n",
            "826/826 - 4s - 4ms/step - loss: 0.0012\n",
            "Epoch 7/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0012\n",
            "Epoch 8/30\n",
            "826/826 - 2s - 3ms/step - loss: 0.0011\n",
            "Epoch 9/30\n",
            "826/826 - 3s - 3ms/step - loss: 0.0011\n",
            "Epoch 10/30\n",
            "826/826 - 3s - 3ms/step - loss: 9.9939e-04\n",
            "Epoch 11/30\n",
            "826/826 - 3s - 4ms/step - loss: 9.8775e-04\n",
            "Epoch 12/30\n",
            "826/826 - 4s - 5ms/step - loss: 8.9880e-04\n",
            "Epoch 13/30\n",
            "826/826 - 3s - 3ms/step - loss: 8.3923e-04\n",
            "Epoch 14/30\n",
            "826/826 - 2s - 3ms/step - loss: 7.6871e-04\n",
            "Epoch 15/30\n",
            "826/826 - 3s - 3ms/step - loss: 7.2267e-04\n",
            "Epoch 16/30\n",
            "826/826 - 3s - 4ms/step - loss: 6.4717e-04\n",
            "Epoch 17/30\n",
            "826/826 - 4s - 5ms/step - loss: 5.9041e-04\n",
            "Epoch 18/30\n",
            "826/826 - 2s - 3ms/step - loss: 5.2878e-04\n",
            "Epoch 19/30\n",
            "826/826 - 3s - 3ms/step - loss: 4.7626e-04\n",
            "Epoch 20/30\n",
            "826/826 - 3s - 3ms/step - loss: 4.2851e-04\n",
            "Epoch 21/30\n",
            "826/826 - 3s - 4ms/step - loss: 3.7897e-04\n",
            "Epoch 22/30\n",
            "826/826 - 4s - 5ms/step - loss: 3.3161e-04\n",
            "Epoch 23/30\n",
            "826/826 - 3s - 3ms/step - loss: 2.8760e-04\n",
            "Epoch 24/30\n",
            "826/826 - 3s - 3ms/step - loss: 2.4788e-04\n",
            "Epoch 25/30\n",
            "826/826 - 3s - 4ms/step - loss: 2.1452e-04\n",
            "Epoch 26/30\n",
            "826/826 - 4s - 5ms/step - loss: 1.8396e-04\n",
            "Epoch 27/30\n",
            "826/826 - 3s - 3ms/step - loss: 1.6070e-04\n",
            "Epoch 28/30\n",
            "826/826 - 3s - 3ms/step - loss: 1.3891e-04\n",
            "Epoch 29/30\n",
            "826/826 - 3s - 3ms/step - loss: 1.1544e-04\n",
            "Epoch 30/30\n",
            "826/826 - 3s - 4ms/step - loss: 9.9809e-05\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3155e-04  \n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6854e-04 \n",
            "Train set MSE with attention = 0.0002442726690787822\n",
            "Test set MSE with attention = 0.00016916888125706464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGJr-Z7TroPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}